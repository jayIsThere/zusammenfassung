---
title: "Prompt Engineering"
author: "Jaehan Kim"
date: 2025-04-10
tags: ["Prompt_Engineering"]
draft: false
---



Basis
-------------

### Technics

#### Literature

1. Alnajashi, A. (2024). Investigating the accuracy of large language models ’chatgpt-4’ in grading students’ writing according to a specific rubric.
2. Hackl, V., M¨ uller, A. E., Granitzer, M., and Sailer, M. (2023). Is gpt-4 a reliable rater? evaluating consistency in gpt-4’s text ratings. Frontiers in Education, 8.
3. Jacobsen, L. and Weber, K. (2023). The promises and pitfalls of chatgpt as a feedback provider in higher education: An exploratory study of prompt engineering and the quality of ai-driven feedback.
4. Jukiewicz, M. (2024). The future of grading programming assignments in education: The role of chatgpt in automating the assessment and feedback process. Thinking Skills and Creativity, 52:101522.
5. Lee, G.-G., Latif, E., Wu, X., Liu, N., and Zhai, X. (2024a). Applying large language models and chain-of-thought for automatic scoring. Computers and Education: Artificial Intelligence, 6:100213.
6. Meyer, J., Jansen, T., Schiller, R., Liebenow, L. W., Steinbach, M., Horbach, A., and Fleckenstein, J. (2024). Using llms to bring evidence-based feedback into the classroom: Ai-generated feedback increases secondary students’ text revision, motivation, and positive emotions. Computers and Education: Artificial Intelligence,
6:100199.
7. Stahl, M., Biermann, L., Nehring, A., and Wachsmuth, H.(2024). Exploring llm prompting strategies for joint essay scoring and feedback generation. Leibniz University Hannover.
