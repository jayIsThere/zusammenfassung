---
title: SLA
author: Jaehan Kim
date: 2025-04-10
category: SLA
layout: post
---


Lineare Algebra
-------------

Lineare Algebra .....

1. Vektoren
2. Lineare Abbildungen und Matrizen
3. Determinanten
4. Spezielle lineare Abbildungen
5. Eigenwerte und Eigenvektoren

# Vektor- und Matrix-Formeln

## Vektor-Formeln

1. **Skalarprodukt (Dot Product)**  
   Das Skalarprodukt von zwei Vektoren $$\( \mathbf{u}, \mathbf{v} \in \mathbb{R}^n \)$$ ist definiert als:
   $$
   \mathbf{u} \cdot \mathbf{v} = \sum_{i=1}^{n} u_i v_i
   $$

2. **Vektorlänge (Norm)**  
   Die Länge (Norm) eines Vektors $$\( \mathbf{a} \in \mathbb{R}^n \)$$ ist gegeben durch:
   $$
   |\mathbf{a}| = \sqrt{a_1^2 + a_2^2 + \dots + a_n^2}
   $$

3. **Winkel zwischen Vektoren (Angle between Vectors)**  
   Der Winkel $$\( \theta \)$$ zwischen den Vektoren $$\( \mathbf{a}, \mathbf{b} \in \mathbb{R}^n \)$$ wird durch die folgende Formel berechnet:
   $$
   \cos(\theta) = \frac{\mathbf{a} \cdot \mathbf{b}}{|\mathbf{a}| |\mathbf{b}|}
   $$

4. **Orthogonalität (Orthogonality)**  
   Zwei Vektoren $$\( \mathbf{a} \)$$ und $$\( \mathbf{b} \)$$ sind orthogonal (rechtwinklig), wenn:
   $$
   \mathbf{a} \cdot \mathbf{b} = 0
   $$

5. **Kreuzprodukt (Cross Product) - In 3D**  
   Das Kreuzprodukt zweier Vektoren $$\( \mathbf{a} = (a_1, a_2, a_3) \)$$ und $$\( \mathbf{b} = (b_1, b_2, b_3) \)$$ ist:
   $$
   \mathbf{a} \times \mathbf{b} = 
   \begin{vmatrix}
   \mathbf{i} & \mathbf{j} & \mathbf{k} \\
   a_1 & a_2 & a_3 \\
   b_1 & b_2 & b_3
   \end{vmatrix}
   = \left( a_2 b_3 - a_3 b_2, \, a_3 b_1 - a_1 b_3, \, a_1 b_2 - a_2 b_1 \right)
   $$

---

## Matrix-Formeln

1. **Matrixmultiplikation (Matrix Multiplication)**  
   Die Multiplikation zweier Matrizen $$\( A \in \mathbb{R}^{m \times n} \)$$ und $$\( B \in \mathbb{R}^{n \times p} \)$$ ergibt:
   $$
   C = AB, \quad C_{ij} = \sum_{k=1}^{n} A_{ik} B_{kj}
   $$

2. **Transponierte Matrix (Transpose of a Matrix)**  
   Die Transponierte einer Matrix $$\( A = [a_{ij}] \)$$ ist:
   $$
   A^T = [a_{ji}]
   $$

3. **Determinante einer Matrix (Determinant of a Matrix)**  
   Die Determinante einer 2x2-Matrix $$\( A = \begin{pmatrix} a & b \\ c & d \end{pmatrix} \)$$ ist:
   $$
   \det(A) = ad - bc
   $$

4. **Inverse Matrix (Inverse Matrix)**  
   Wenn die Matrix $$\( A \)$$ invertierbar ist, dann ist die Inverse von $$\( A \)$$:
   $$
   A^{-1} = \frac{1}{\det(A)} \text{adj}(A)
   $$
   wobei $$\( \text{adj}(A) \)$$ die adjungierte Matrix von $$\( A \)$$ ist.

5. **Eigenwerte und Eigenvektoren (Eigenvalues and Eigenvectors)**  
   Die Eigenwerte $$\( \lambda \)$$ und Eigenvektoren $$\( \mathbf{v} \)$$ einer Matrix $$\( A \)$$ erfüllen die Gleichung:
   $$
   A \mathbf{v} = \lambda \mathbf{v}
   $$

6. **Lösung eines linearen Systems (Solution of a Linear System)**  
   Die Lösung des linearen Systems $$\( A \mathbf{x} = \mathbf{b} \)$$ ist:
   $$
   \mathbf{x} = A^{-1} \mathbf{b}, \quad \text{wenn } A \text{ invertierbar ist.}
   $$





#### Determinanten

...

#### Spezielle lineare Abbildungen

...

#### Eigenwerte und Eigenvektoren

...

Statistik
-------------

Statistik .....

1. Deskriptive Statistik: Kennzahlen und empirische Verteilungen
2. Diskrete Zufallsvariablen
3. Kontinuierliche Zufallsvariablen
4. statistische Tests
5. Schätzer
6. Regression

### Deskriptive Statistik: Kennzahlen und empirische Verteilungen

...

### Diskrete Zufallsvariablen

...

### Kontinuierliche Zufallsvariablen

...

### statistische Tests

...

### Schätzer

...

### Regression

...

